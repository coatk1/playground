{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from typing import Dict, List, Union\n\ndef get_leaves(item: Union[Dict, List], key=None):\n    \"\"\"Return all key: values recursively.\n    \n    Parameters\n    ----------\n    item: dict\n        The dictionary.\n    \n    key: dict\n        The key.\n    \n    Returns\n    -------\n    Return key: values recursively.\n    \"\"\"\n    try:\n        if isinstance(item, dict):\n            leaves = {}\n\n            for i in item.keys():\n                leaves.update(get_leaves(item[i], i))\n            return leaves\n\n        elif isinstance(item, list):\n            leaves = {}\n\n            for i in item:\n                leaves.update(get_leaves(i, key))\n            return leaves\n\n        else:\n            return {key: item}\n\n    except Exception as e:\n        print(e)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Paths"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standard Libraries\nimport os\nimport glob\nimport json\nimport getpass\nimport pathlib\n\n# Third-party Libraries\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Home drive\nHOME_DRIVE = str(pathlib.Path.home())\n\n# Paths\nOTHER_DRIVE = \"C:\\\\\"\next = \"csv\"\n\nsome_path = \"path\\\\to\\\\file\"\npath = os.path.join(HOME_DRIVE, some_path)\n\n# wp = getpass.getpass(\"Enter: \")\n\nfull_path = glob.glob(\"{}\\\\*.{}\".format(path, ext))\n# os.path.isfile(full_path)\n\npd.concat([pd.read_csv(_) for _ in full_path])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Read/ Write Files"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standard Libraries\nimport csv\n\n# Third-party Libraries\n# import ijson\n\n# Read in a file\nwith open(file, \"r\") as f:\n\n    # Read json file\n    if file.endswith(\"json\"):\n\n        # Loads json object as a string\n        data = json.load(f)\n        \n        # Loads json string into dictionary\n        new_data = json.loads(data)\n    \n    # Rad csv file\n    elif file.endswith(\"csv\"):\n        \n        # reader = csv.reader(f, delimiter=\",\")\n        reader = csv.DictReader(f)\n\n# # Write to a csv file\n# with open(file, \"w\") as outfile:\n#     json.dump(data, outfile)\n\n# # Write to a csv file\n# f = csv.writer(open(\"text.csv\", \"w\"))\n# f.writerow([\"Column_Name\"])\n# f.writerow([\"rows\"])","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pd.DataFrame(data)\n# pd.read_json(file, orient=\"columns\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Json"},{"metadata":{"trusted":true},"cell_type":"code","source":"# json.dumps([dict1, dict2])\n# json.loads(json.dumps([dict1, dict2]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Batch large json files"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Funstion for generator\n# def batch_large_file(filename):\n#     for i in open(filename, \"r\"):\n#         yield i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Generator\n# file = batch_large_file(big_file)\n\n# # Count to append on different files\n# counter = 1\n\n# for f in files:\n    \n#     # Add number to file\n#     new_file = \"batch/batch_{}.json\".format(str(counter))\n    \n#     # Write to a json file\n#     with open(new_file, \"w\") as output:\n#         json.dump(f, output)\n        \n#     counter += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## API"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standard Libraries\nimport re\nimport base64\nimport urllib\nimport requests\nimport traceback\n\n# Third-party Libraries\nimport pprint\nimport xmltodict\nimport elasticsearch\nfrom io import StringIO\nfrom bs4 import BeautifulSoup, SoupStrainer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keywords = \"avengers\"\n\n# Use urllib to parse query string. Helps to reformat in url parameters in a friendly way.\nquery = urllib.parse.quote_plus(keywords)\n\nbase = \"\"\n\nurl = base + \"q=\" + query\n\nrequest_body = {\n    \"key\": \"value\"\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"session = requests.Session()\n\ntry:\n    \n    # Disable urllib warning\n    requests.packages.urllib3.disable_warnings(\n        requests.packages.urllib3.exceptions.SecurityWarning\n    )\n    \n    # request = session.get(url, headers={\"content-type\": \"application/json\"})\n    request = session.post(\n        url,\n        # cert=(cer,key),\n        json=request_body,\n        headers={\"content-type\": \"application/json\"},\n        verify=False,\n        allow_redirects=False,\n        stream=True,\n    )\nexcept Exception as e:\n    traceback.print_exc()\n    print(type(e))\n    print(e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"requests.text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Source: https://github.com/fhightower/html-to-json/blob/main/html_to_json/convert_html.py\n\n# HTML\nif \"HTML\" in requests.text:\n    json_data = convert_html.convert(requests.text)\n\n# XML\nelif \"xml\" in requests.text:\n    json_string = json.dumps(xmltodict.parse(requests.text))\n    json_data = json.loads(json_string)\n    \nelse:\n    json_data = request.json()\n    # json_data = json.loads(requests.text)\n\njson_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# BeautifulSoup\nsoup = BeautifulSoup(requests.content, \"xml\")  # html.parser","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"soup.find(\"title\").get_text()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"re.sub(\"\\n\", \"\", soup.find(\"body\").get_text())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Remove white spaces\n# [i for in soup.stripped_strings]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_df_list = []\n\nfor i in json_data:\n    \n    if type(json_data[i]) == list:\n        for j in json_data[i]:\n            # _df_list.append(get_leaves(j))\n            _df_list.append(pd.json_normalize(j))\n\npd.concat(_df_list, ignore_index=True, sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dict([(k, Series(v)) for k, v in json_data.items()])\n# pd.from_dict(json_data, orient=\"index\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Regex"},{"metadata":{"trusted":true},"cell_type":"code","source":"re.findall(\"[0-9a-zA-Z]\", \"(1,2,3,4,5)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"# e_df[\"eml\"].str.extract(\"\\<(.*?)>\\\\\", expand=True)\n# e_df.loc[(e_df[\"eml\"].str.contains(\"@\")) & ~(e_df[\"eml\"].str.contains(\"<\")), \"to\"] = e_df.loc[(e_df[\"eml\"].str.contains(\"@\")) & ~(e_df[\"eml\"].str.contains(\"<\")), \"from\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Split columns\n# df[\"a\"], df[\"b\"] = df[\"ab\"].str.split(\",\", 1).str","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Indexing\n# pd.at[index, column]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Formatting\n# pd.map(\"{:,.2f}\".format)\n# pd.to_string(formatters={\"cost\": \"{:,.2f}\".format})\n# pd.options.display.float_format = \"{:,.2f}\".format","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dates.apply(lambda x:x.strftime(\"%Y-%m-%d\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pd.groupby([...])[].sum.unstack(fill_value=0).reset_index().rename_axis(None, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":5}